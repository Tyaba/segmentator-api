{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yoshino_teppei/ghq/github.com/Tyaba/segmenter-api\n",
      "/home/yoshino_teppei/ghq/github.com/Tyaba/segmenter-api\n"
     ]
    }
   ],
   "source": [
    "from segmenter_api.utils.file import get_project_dir\n",
    "\n",
    "%cd {get_project_dir()}\n",
    "print(get_project_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.auto.modeling_auto import AutoModelForCausalLM\n",
    "from transformers.models.auto.processing_auto import AutoProcessor\n",
    "import torch\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"models/microsoft/Florence-2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一回のみ実行すればローカルに保存される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Florence-2-large\",\n",
    "    torch_dtype=torch_dtype,\n",
    "    trust_remote_code=True,\n",
    "    use_safetensors=True,\n",
    ")\n",
    "model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"microsoft/Florence-2-large\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "processor.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルから読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoshino_teppei/ghq/github.com/Tyaba/segmenter-api/.venv/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Some weights of Florence2ForConditionalGeneration were not initialized from the model checkpoint at models/microsoft/Florence-2-large and are newly initialized: ['language_model.lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch_dtype, trust_remote_code=True, use_safetensors=True)\n",
    "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
